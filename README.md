# Probabilistic Knowledge Structure Estimation

This repository provides a pipeline for estimating a **probabilistic knowledge structure (PKS)** from binary student response data to programming tasks. 

It uses a combination of:

- **IITA (Inductive Item Tree Analysis)** to infer prerequisite implications between tasks,
- **Closure-based generation** of feasible knowledge states,
- **BLIM (Basic Local Independence Model)** to fit a probabilistic model of student knowledge.

The code supports visualizing the knowledge structure and estimating slip/guess parameters and state probabilities.

This is an edited fork of: https://github.com/milansegedinac/kst 

---

## Features

- Estimate implications between tasks using IITA
- Construct feasible knowledge states from implications
- Visualize the knowledge structure using a Hasse diagram
- Fit a probabilistic model (BLIM) to student data

---

## Project Structure

```

.
├── data/
│   └── scores.csv             # Input data file: binary student task performance (0/1)
├── implications.txt           # Saved implication base (optional)
├── main.py                    # Main analysis script
├── README.md                  

````

---

##  Theoretical Background

1. **Step 1: Knowledge Structure Estimation**
   - We use **IITA** to infer implications such as `q1 ⇒ q3`.
   - From these, we construct the **closure system** — a set of feasible knowledge states.

2. **Step 2: Probabilistic Model (BLIM)**
   - Using the BLIM, we estimate:
     - The probability of each knowledge state `P(K)`
     - Slip (false negative) and guess (false positive) parameters per task
   - The model is fit using the Minimum Discrepancy method.

3. **Step 3: Student Diagnosis (planned)**
   - Use the fitted model to infer the most likely knowledge state of a student
   - Recommend tasks the student is ready to learn

---

## How to Run

### 1. Prepare Input Data

Your input should be a CSV file (e.g., `data/scores.csv`) with rows as students and columns as tasks. Entries must be binary (`0` = incorrect / not mastered, `1` = correct / mastered).

```csv
q1,q2,q3,q4
1,0,1,1
0,1,0,0
...
````

### 2. Run the Analysis

```bash
python main.py --rows 100
```

**Options:**

* `--rows`: Number of student responses to sample (default: 10)
* `--load_implications`: Load implications from `implications.txt` instead of running IITA

### 3. Output

* Printed implications and error rate from IITA
* `implications.txt`: Stores the implications found
* Hasse diagram visualizing the knowledge structure
* Printed summary of the BLIM model:

  * State probabilities
  * Slip/guess parameters

---

## Dependencies

Install required libraries:

```bash
pip install -r requirements.txt
```

The core logic relies on modules in [`learning_spaces/`](./learning_spaces/) — a custom package implementing IITA, state generation, BLIM, and Hasse diagram visualization.

---

